{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Load packages\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import TimeDistributed, Conv1D, Dense, Embedding, Input, Dropout, LSTM, Bidirectional, MaxPooling1D, Flatten, concatenate\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import SGD, Nadam\n",
    "import pydot\n",
    "import pydotplus\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import os\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Method to compute the accuracy.\n",
    "def compute_f1(predictions, correct, idx2Label):\n",
    "    label_pred = []\n",
    "    for sentence in predictions:\n",
    "        label_pred.append([idx2Label[element] for element in sentence])\n",
    "\n",
    "    label_correct = []\n",
    "    for sentence in correct:\n",
    "        label_correct.append([idx2Label[element] for element in sentence])\n",
    "\n",
    "    prec = compute_precision(label_pred, label_correct)\n",
    "    rec = compute_precision(label_correct, label_pred)\n",
    "\n",
    "    f1 = 0\n",
    "    if (rec + prec) > 0:\n",
    "        f1 = 2.0 * prec * rec / (prec + rec);\n",
    "\n",
    "    return prec, rec, f1\n",
    "\n",
    "\n",
    "def compute_precision(guessed_sentences, correct_sentences):\n",
    "    assert (len(guessed_sentences) == len(correct_sentences))\n",
    "    correctCount = 0\n",
    "    count = 0\n",
    "\n",
    "    for sentenceIdx in range(len(guessed_sentences)):\n",
    "        guessed = guessed_sentences[sentenceIdx]\n",
    "        correct = correct_sentences[sentenceIdx]\n",
    "        assert (len(guessed) == len(correct))\n",
    "        idx = 0\n",
    "        while idx < len(guessed):\n",
    "            if guessed[idx][0] == 'B':  # a new chunk starts\n",
    "                count += 1\n",
    "\n",
    "                if guessed[idx] == correct[idx]:  # first prediction correct\n",
    "                    idx += 1\n",
    "                    correctlyFound = True\n",
    "\n",
    "                    while idx < len(guessed) and guessed[idx][0] == 'I':  # scan entire chunk\n",
    "                        if guessed[idx] != correct[idx]:\n",
    "                            correctlyFound = False \n",
    "\n",
    "                        idx += 1\n",
    "\n",
    "                    if idx < len(guessed):\n",
    "                        if correct[idx][0] == 'I':  # chunk in correct was longer\n",
    "                            correctlyFound = False\n",
    "\n",
    "                    if correctlyFound:\n",
    "                        correctCount += 1\n",
    "                else:\n",
    "                    idx += 1\n",
    "            else:\n",
    "                idx += 1\n",
    "\n",
    "    precision = 0\n",
    "    if count > 0:\n",
    "        precision = float(correctCount) / count\n",
    "\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "def readfile(filename, *, encoding=\"UTF8\"):\n",
    "    '''\n",
    "    read file\n",
    "    return format :\n",
    "    [ ['EU', 'B-ORG'], ['rejects', 'O'], ['German', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['British', 'B-MISC'], ['lamb', 'O'], ['.', 'O'] ]\n",
    "    '''\n",
    "    with open(filename, mode='rt', encoding=encoding) as f:\n",
    "        sentences = []\n",
    "        sentence = []\n",
    "        for line in f:\n",
    "            if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == \"\\n\":\n",
    "                if len(sentence) > 0:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "                continue\n",
    "            splits = line.split(' ')\n",
    "            sentence.append([splits[0], splits[-1]])\n",
    "\n",
    "    if len(sentence) > 0:\n",
    "        sentences.append(sentence)\n",
    "        sentence = []\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# define casing s.t. NN can use case information to learn patterns\n",
    "def getCasing(word, caseLookup):\n",
    "    casing = 'other'\n",
    "\n",
    "    numDigits = 0\n",
    "    for char in word:\n",
    "        if char.isdigit():\n",
    "            numDigits += 1\n",
    "\n",
    "    digitFraction = numDigits / float(len(word))\n",
    "\n",
    "    if word.isdigit():  # Is a digit\n",
    "        casing = 'numeric'\n",
    "    elif digitFraction > 0.5:\n",
    "        casing = 'mainly_numeric'\n",
    "    elif word.islower():  # All lower case\n",
    "        casing = 'allLower'\n",
    "    elif word.isupper():  # All upper case\n",
    "        casing = 'allUpper'\n",
    "    elif word[0].isupper():  \n",
    "        casing = 'initialUpper'\n",
    "    elif numDigits > 0:\n",
    "        casing = 'contains_digit'\n",
    "\n",
    "    return caseLookup[casing]\n",
    "\n",
    "\n",
    "# return batches ordered by words in sentence\n",
    "def createEqualBatches(data):\n",
    "\n",
    "    \n",
    "    n_batches = 100\n",
    "    batch_size = len(data) // n_batches\n",
    "    num_words = [batch_size*(i+1) for i in range(0, n_batches)]\n",
    "    \n",
    "    batches = []\n",
    "    batch_len = []\n",
    "    z = 0\n",
    "    start = 0\n",
    "    for end in num_words:\n",
    "        # print(\"start\", start)\n",
    "        for batch in data[start:end]:\n",
    "            # if len(batch[0]) == i:  # if sentence has i words\n",
    "            batches.append(batch)\n",
    "            z += 1\n",
    "        batch_len.append(z)\n",
    "        start = end\n",
    "\n",
    "    return batches, batch_len\n",
    "\n",
    "def createBatches(data):\n",
    "    l = []\n",
    "    for i in data:\n",
    "        l.append(len(i[0]))\n",
    "    l = set(l)\n",
    "    batches = []\n",
    "    batch_len = []\n",
    "    z = 0\n",
    "    for i in l:\n",
    "        for batch in data:\n",
    "            if len(batch[0]) == i:\n",
    "                batches.append(batch)\n",
    "                z += 1\n",
    "        batch_len.append(z)\n",
    "    return batches,batch_len\n",
    "\n",
    "\n",
    "# returns matrix with 1 entry = list of 4 elements:\n",
    "# word indices, case indices, character indices, label indices\n",
    "def createMatrices(sentences, word2Idx, label2Idx, case2Idx, char2Idx):\n",
    "    unknownIdx = word2Idx['UNKNOWN_TOKEN']\n",
    "    paddingIdx = word2Idx['PADDING_TOKEN']\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    wordCount = 0\n",
    "    unknownWordCount = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        wordIndices = []\n",
    "        caseIndices = []\n",
    "        charIndices = []\n",
    "        labelIndices = []\n",
    "\n",
    "        for word, char, label in sentence:\n",
    "            wordCount += 1\n",
    "            if word in word2Idx:\n",
    "                wordIdx = word2Idx[word]\n",
    "            elif word.lower() in word2Idx:\n",
    "                wordIdx = word2Idx[word.lower()]\n",
    "            else:\n",
    "                wordIdx = unknownIdx\n",
    "                unknownWordCount += 1\n",
    "            charIdx = []\n",
    "            for x in char:\n",
    "                charIdx.append(char2Idx[x])\n",
    "            # Get the label and map to int\n",
    "            wordIndices.append(wordIdx)\n",
    "            caseIndices.append(getCasing(word, case2Idx))\n",
    "            charIndices.append(charIdx)\n",
    "            labelIndices.append(label2Idx[label])\n",
    "\n",
    "        dataset.append([wordIndices, caseIndices, charIndices, labelIndices])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def iterate_minibatches(dataset, batch_len):\n",
    "    start = 0\n",
    "    for i in batch_len:\n",
    "        tokens = []\n",
    "        caseing = []\n",
    "        char = []\n",
    "        labels = []\n",
    "        data = dataset[start:i]\n",
    "        start = i\n",
    "        for dt in data:\n",
    "            t, c, ch, l = dt\n",
    "            l = np.expand_dims(l, -1)\n",
    "            tokens.append(t)\n",
    "            caseing.append(c)\n",
    "            char.append(ch)\n",
    "            labels.append(l)\n",
    "        \n",
    "        yield np.asarray(labels), np.asarray(tokens), np.asarray(caseing), np.asarray(char)        \n",
    "\n",
    "\n",
    "# returns data with character information in format\n",
    "# [['EU', ['E', 'U'], 'B-ORG\\n'], ...]\n",
    "def addCharInformation(Sentences):\n",
    "    for i, sentence in enumerate(Sentences):\n",
    "        for j, data in enumerate(sentence):\n",
    "            chars = [c for c in data[0]]\n",
    "            Sentences[i][j] = [data[0], chars, data[1]]\n",
    "    return Sentences\n",
    "\n",
    "\n",
    "# 0-pads all words\n",
    "def padding(Sentences):\n",
    "    maxlen = 52\n",
    "    for sentence in Sentences:\n",
    "        char = sentence[2]\n",
    "        for x in char:\n",
    "            maxlen = max(maxlen, len(x))\n",
    "    for i, sentence in enumerate(Sentences):\n",
    "        Sentences[i][2] = pad_sequences(Sentences[i][2], 52, padding='post')\n",
    "    return Sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class initialised.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Initialise class\"\"\"\n",
    "\n",
    "class CNN_BLSTM(object):\n",
    "    \n",
    "    def __init__(self, EPOCHS, DROPOUT, DROPOUT_RECURRENT, LSTM_STATE_SIZE, CONV_SIZE, LEARNING_RATE, OPTIMIZER):\n",
    "        \n",
    "        self.epochs = EPOCHS\n",
    "        self.dropout = DROPOUT\n",
    "        self.dropout_recurrent = DROPOUT_RECURRENT\n",
    "        self.lstm_state_size = LSTM_STATE_SIZE\n",
    "        self.conv_size = CONV_SIZE\n",
    "        self.learning_rate = LEARNING_RATE\n",
    "        self.optimizer = OPTIMIZER\n",
    "        \n",
    "    def loadData(self):\n",
    "        \"\"\"Load data and add character information\"\"\"\n",
    "        self.trainSentences = readfile(\"data/train.txt\")\n",
    "        self.devSentences = readfile(\"data/testb.txt\")\n",
    "        self.testSentences = readfile(\"data/testa.txt\")\n",
    "\n",
    "    def addCharInfo(self):\n",
    "        # format: [['EU', ['E', 'U'], 'B-ORG\\n'], ...]\n",
    "        self.trainSentences = addCharInformation(self.trainSentences)\n",
    "        self.devSentences = addCharInformation(self.devSentences)\n",
    "        self.testSentences = addCharInformation(self.testSentences)\n",
    "\n",
    "    def embed(self):\n",
    "        \"\"\"Create word- and character-level embeddings\"\"\"\n",
    "\n",
    "        labelSet = set()\n",
    "        words = {}\n",
    "\n",
    "        # unique words and labels in data  \n",
    "        for dataset in [self.trainSentences, self.devSentences, self.testSentences]:\n",
    "            for sentence in dataset:\n",
    "                for token, char, label in sentence:\n",
    "                    # token ... token, char ... list of chars, label ... BIO labels   \n",
    "                    labelSet.add(label)\n",
    "                    words[token.lower()] = True\n",
    "\n",
    "        # mapping for labels\n",
    "        self.label2Idx = {}\n",
    "        for label in labelSet:\n",
    "            self.label2Idx[label] = len(self.label2Idx)\n",
    "\n",
    "        # mapping for token cases\n",
    "        case2Idx = {'numeric': 0, 'allLower': 1, 'allUpper': 2, 'initialUpper': 3, 'other': 4, 'mainly_numeric': 5,\n",
    "                    'contains_digit': 6, 'PADDING_TOKEN': 7}\n",
    "        self.caseEmbeddings = np.identity(len(case2Idx), dtype='float32')  # identity matrix used \n",
    "\n",
    "        # read GLoVE word embeddings\n",
    "        word2Idx = {}\n",
    "        self.wordEmbeddings = []\n",
    "\n",
    "        fEmbeddings = open(\"embeddings/glove.6B.50d.txt\", encoding=\"utf-8\")\n",
    "\n",
    "        # loop through each word in embeddings\n",
    "        for line in fEmbeddings:\n",
    "            split = line.strip().split(\" \")\n",
    "            word = split[0]  # embedding word entry\n",
    "\n",
    "            if len(word2Idx) == 0:  # add padding+unknown\n",
    "                word2Idx[\"PADDING_TOKEN\"] = len(word2Idx)\n",
    "                vector = np.zeros(len(split) - 1)  # zero vector for 'PADDING' word\n",
    "                self.wordEmbeddings.append(vector)\n",
    "\n",
    "                word2Idx[\"UNKNOWN_TOKEN\"] = len(word2Idx)\n",
    "                vector = np.random.uniform(-0.25, 0.25, len(split) - 1)\n",
    "                self.wordEmbeddings.append(vector)\n",
    "\n",
    "            if split[0].lower() in words:\n",
    "                vector = np.array([float(num) for num in split[1:]])\n",
    "                self.wordEmbeddings.append(vector)  # word embedding vector\n",
    "                word2Idx[split[0]] = len(word2Idx)  # corresponding word dict\n",
    "\n",
    "        self.wordEmbeddings = np.array(self.wordEmbeddings)\n",
    "\n",
    "        # dictionary of all possible characters\n",
    "        self.char2Idx = {\"PADDING\": 0, \"UNKNOWN\": 1}\n",
    "        for c in \" 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ.,-_()[]{}!?:;#'\\\"/\\\\%$`&=*+@^~|<>\":\n",
    "            self.char2Idx[c] = len(self.char2Idx)\n",
    "\n",
    "        # format: [[wordindices], [caseindices], [padded word indices], [label indices]]\n",
    "        self.train_set = padding(createMatrices(self.trainSentences, word2Idx, self.label2Idx, case2Idx, self.char2Idx))\n",
    "        self.dev_set = padding(createMatrices(self.devSentences, word2Idx, self.label2Idx, case2Idx, self.char2Idx))\n",
    "        self.test_set = padding(createMatrices(self.testSentences, word2Idx, self.label2Idx, case2Idx, self.char2Idx))\n",
    "\n",
    "        self.idx2Label = {v: k for k, v in self.label2Idx.items()}\n",
    "        \n",
    "    def createBatches(self):\n",
    "        \"\"\"Create batches\"\"\"\n",
    "        self.train_batch, self.train_batch_len = createBatches(self.train_set)\n",
    "        self.dev_batch, self.dev_batch_len = createBatches(self.dev_set)\n",
    "        self.test_batch, self.test_batch_len = createBatches(self.test_set)\n",
    "        \n",
    "    def tag_dataset(self, dataset, model):\n",
    "        \"\"\"Tag data with numerical values\"\"\"\n",
    "        correctLabels = []\n",
    "        predLabels = []\n",
    "        for i, data in enumerate(dataset):\n",
    "            tokens, casing, char, labels = data\n",
    "            tokens = np.asarray([tokens])\n",
    "            casing = np.asarray([casing])\n",
    "            char = np.asarray([char])\n",
    "            pred = model.predict([tokens, casing, char], verbose=False)[0]\n",
    "            pred = pred.argmax(axis=-1)  # Predict the classes\n",
    "            correctLabels.append(labels)\n",
    "            predLabels.append(pred)\n",
    "        return predLabels, correctLabels\n",
    "    \n",
    "    def buildModel(self):\n",
    "        \"\"\"Model layers\"\"\"\n",
    "\n",
    "        # character input\n",
    "        character_input = Input(shape=(None, 52,), name=\"Character_input\")\n",
    "        embed_char_out = TimeDistributed(\n",
    "            Embedding(len(self.char2Idx), 30, embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name=\"Character_embedding\")(\n",
    "            character_input)\n",
    "\n",
    "        dropout = Dropout(self.dropout)(embed_char_out)\n",
    "\n",
    "        # CNN\n",
    "        conv1d_out = TimeDistributed(Conv1D(kernel_size=self.conv_size, filters=30, padding='same', activation='tanh', strides=1), name=\"Convolution\")(dropout)\n",
    "        maxpool_out = TimeDistributed(MaxPooling1D(52), name=\"Maxpool\")(conv1d_out)\n",
    "        char = TimeDistributed(Flatten(), name=\"Flatten\")(maxpool_out)\n",
    "        char = Dropout(self.dropout)(char)\n",
    "\n",
    "        # word-level input\n",
    "        words_input = Input(shape=(None,), dtype='int32', name='words_input')\n",
    "        words = Embedding(input_dim=self.wordEmbeddings.shape[0], output_dim=self.wordEmbeddings.shape[1], weights=[self.wordEmbeddings],\n",
    "                          trainable=False)(words_input)\n",
    "\n",
    "        # case-info input\n",
    "        casing_input = Input(shape=(None,), dtype='int32', name='casing_input')\n",
    "        casing = Embedding(output_dim=self.caseEmbeddings.shape[1], input_dim=self.caseEmbeddings.shape[0], weights=[self.caseEmbeddings],\n",
    "                           trainable=False)(casing_input)\n",
    "\n",
    "        # concat & BLSTM\n",
    "        output = concatenate([words, casing, char])\n",
    "        output = Bidirectional(LSTM(self.lstm_state_size, \n",
    "                                    return_sequences=True, \n",
    "                                    dropout=self.dropout,                        # on input to each LSTM block\n",
    "                                    recurrent_dropout=self.dropout_recurrent     # on recurrent input signal\n",
    "                                   ), name=\"BLSTM\")(output)\n",
    "        output = TimeDistributed(Dense(len(self.label2Idx), activation='softmax'),name=\"Softmax_layer\")(output)\n",
    "\n",
    "        # set up model\n",
    "        self.model = Model(inputs=[words_input, casing_input, character_input], outputs=[output])\n",
    "        \n",
    "        self.model.compile(loss='sparse_categorical_crossentropy', optimizer=self.optimizer)\n",
    "        \n",
    "        self.init_weights = self.model.get_weights()\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "\n",
    "        self.f1_test_history = []\n",
    "        self.f1_dev_history = []\n",
    "\n",
    "        for epoch in range(self.epochs):    \n",
    "            print(\"Epoch {}/{}\".format(epoch, self.epochs))\n",
    "            for i,batch in enumerate(iterate_minibatches(self.train_batch,self.train_batch_len)):\n",
    "                labels, tokens, casing,char = batch       \n",
    "                self.model.train_on_batch([tokens, casing,char], labels)\n",
    "\n",
    "            # compute F1 scores\n",
    "            predLabels, correctLabels = self.tag_dataset(self.test_batch, self.model)\n",
    "            pre_test, rec_test, f1_test = compute_f1(predLabels, correctLabels, self.idx2Label)\n",
    "            self.f1_test_history.append(f1_test)\n",
    "            print(\"f1 testa \", round(f1_test, 4))\n",
    "\n",
    "            predLabels, correctLabels = self.tag_dataset(self.dev_batch, self.model)\n",
    "            pre_dev, rec_dev, f1_dev = compute_f1(predLabels, correctLabels, self.idx2Label)\n",
    "            self.f1_dev_history.append(f1_dev)\n",
    "            print(\"f1 testb \", round(f1_dev, 4), \"\\n\")\n",
    "            \n",
    "        print(\"Final F1 test score: \", f1_test)\n",
    "            \n",
    "        print(\"Training finished.\")\n",
    "            \n",
    "        # save model\n",
    "        self.modelName = \"{}_{}_{}_{}_{}_{}_{}\".format(self.epochs, \n",
    "                                                        self.dropout, \n",
    "                                                        self.dropout_recurrent, \n",
    "                                                        self.lstm_state_size,\n",
    "                                                        self.conv_size,\n",
    "                                                        self.learning_rate,\n",
    "                                                        self.optimizer.__class__.__name__\n",
    "                                                       )\n",
    "        \n",
    "        modelName = self.modelName + \".h5\"\n",
    "        self.model.save(modelName)\n",
    "        print(\"Model weights saved.\")\n",
    "        \n",
    "        self.model.set_weights(self.init_weights)  # clear model\n",
    "        print(\"Model weights cleared.\")\n",
    "\n",
    "    def writeToFile(self):\n",
    "        \"\"\"Write output to file\"\"\"\n",
    "\n",
    "        # .txt file format\n",
    "        # [epoch  ]\n",
    "        # [f1_test]\n",
    "        # [f1_dev ]\n",
    "        \n",
    "        output = np.matrix([[int(i) for i in range(self.epochs)], self.f1_test_history, self.f1_dev_history])\n",
    "\n",
    "        fileName = self.modelName + \".txt\"\n",
    "        with open(fileName,'wb') as f:\n",
    "            for line in output:\n",
    "                np.savetxt(f, line, fmt='%.5f')\n",
    "                \n",
    "        print(\"Model performance written to file.\")\n",
    "\n",
    "    print(\"Class initialised.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Set parameters\"\"\"\n",
    "\n",
    "EPOCHS = 2               \n",
    "DROPOUT = 0.5             \n",
    "DROPOUT_RECURRENT = 0.25  \n",
    "LSTM_STATE_SIZE = 200     \n",
    "CONV_SIZE = 3             \n",
    "LEARNING_RATE = 0.0105    \n",
    "OPTIMIZER = Nadam()       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "f1 testa  0.4219\n",
      "f1 testb  0.4521 \n",
      "\n",
      "Epoch 1/2\n",
      "f1 testa  0.621\n",
      "f1 testb  0.655 \n",
      "\n",
      "Final F1 test score:  0.6209516573273814\n",
      "Training finished.\n",
      "Model weights saved.\n",
      "Model weights cleared.\n",
      "Model performance written to file.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Construct and run model\"\"\"\n",
    "\n",
    "cnn_blstm = CNN_BLSTM(EPOCHS, DROPOUT, DROPOUT_RECURRENT, LSTM_STATE_SIZE, CONV_SIZE, LEARNING_RATE, OPTIMIZER)\n",
    "cnn_blstm.loadData()\n",
    "cnn_blstm.addCharInfo()\n",
    "cnn_blstm.embed()\n",
    "cnn_blstm.createBatches()\n",
    "cnn_blstm.buildModel()\n",
    "cnn_blstm.train()\n",
    "cnn_blstm.writeToFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation achieves a test F1 score of 0.8329 with 10 epochs. \n",
    "Increase the number of epochs to 30 reach an F1 over 0.88."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnn_blstm.f1_test_history, label = \"F1 testa\")\n",
    "plt.plot(cnn_blstm.f1_dev_history, label = \"F1 testb\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"F1 score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-ORG: 3.1%\n",
      "I-ORG: 1.82%\n",
      "B-MISC: 1.69%\n",
      "I-MISC: 0.57%\n",
      "B-LOC: 3.51%\n",
      "I-LOC: 0.57%\n",
      "B-PER: 3.24%\n",
      "I-PER: 2.22%\n",
      "O: 83.28%\n"
     ]
    }
   ],
   "source": [
    "cnn_blstm = CNN_BLSTM(EPOCHS, DROPOUT, DROPOUT_RECURRENT, LSTM_STATE_SIZE, CONV_SIZE, LEARNING_RATE, OPTIMIZER)\n",
    "cnn_blstm.loadData()\n",
    "\n",
    "category_count = {\"B-ORG\\n\": 0, \"I-ORG\\n\":0, \"B-MISC\\n\": 0, \"I-MISC\\n\":0, \"B-LOC\\n\": 0, \"I-LOC\\n\": 0, \"B-PER\\n\": 0, \"I-PER\\n\": 0, \"O\\n\": 0}\n",
    "total_count = 0\n",
    "\n",
    "for sentence in cnn_blstm.trainSentences:\n",
    "    for word in sentence:\n",
    "        if word[1] in category_count.keys():\n",
    "            category_count[word[1]] += 1\n",
    "            total_count += 1\n",
    "\n",
    "for category, count in category_count.items():\n",
    "    print(\"{}: {}%\".format(category.replace(\"\\n\", \"\"), round((count/total_count)*100, 2)))      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
